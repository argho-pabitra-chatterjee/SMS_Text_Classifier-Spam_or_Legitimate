{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict_SPAM_HAM-TextClassifier.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "collapsed": false,
        "id": "KItB-hGSGUPy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# import required packages"
      ]
    },
    {
      "metadata": {
        "id": "WmWLJ7ONGUP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cross_validation import train_test_split \n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HSiypCGFGUQH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# read the input dataset"
      ]
    },
    {
      "metadata": {
        "id": "RF7rEelgGUQJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "csv_dataset = pd.read_csv('../data/spam.csv', encoding='latin-1')\n",
        "\n",
        "del csv_dataset['Unnamed: 2']\n",
        "del csv_dataset['Unnamed: 3']\n",
        "del csv_dataset['Unnamed: 4']\n",
        "\n",
        "csv_dataset.columns = ['class', 'data']\n",
        "\n",
        "def table(df, col):\n",
        "    return df.groupby(col).count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yi0ggq7gGUQT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imbalanced class proportion observed in distribution of response variable."
      ]
    },
    {
      "metadata": {
        "id": "THWpa9rTGUQW",
        "colab_type": "code",
        "colab": {},
        "outputId": "8872fc1f-56d2-4ff8-ccee-f524c21b711c"
      },
      "cell_type": "code",
      "source": [
        "table(csv_dataset,\"class\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>4825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>747</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       data\n",
              "class      \n",
              "ham    4825\n",
              "spam    747"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "5rFgv1YmGUQq",
        "colab_type": "code",
        "colab": {},
        "outputId": "ea85382a-921b-448c-9d24-b0dead143e62"
      },
      "cell_type": "code",
      "source": [
        "print(csv_dataset.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  class                                               data\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BmJlnMDNGUQ3",
        "colab_type": "code",
        "colab": {},
        "outputId": "092a481a-4eda-4292-ef2f-51454169b515"
      },
      "cell_type": "code",
      "source": [
        "# converting responses to int\n",
        "csv_dataset.loc[csv_dataset['class']=='ham', 'class'] = 0\n",
        "csv_dataset.loc[csv_dataset['class']=='spam', 'class'] = 1\n",
        "\n",
        "print(csv_dataset.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  class                                               data\n",
            "0     0  Go until jurong point, crazy.. Available only ...\n",
            "1     0                      Ok lar... Joking wif u oni...\n",
            "2     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3     0  U dun say so early hor... U c already then say...\n",
            "4     0  Nah I don't think he goes to usf, he lives aro...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ghHfiJLjGURC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## No. of examples belonging to class \"SPAM\" is far too less compared to number of examples for class \"HAM\"\n",
        "## seperating dependent and independent variables\n",
        "y_class = csv_dataset.pop('class')\n",
        "X_data  = csv_dataset['data'].str.strip()\n",
        "\n",
        "## splitting dataset\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_data, y_class, test_size = 0.3, stratify=y_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bRDa7qvFGURK",
        "colab_type": "code",
        "colab": {},
        "outputId": "ceef4809-bccd-443e-e0e9-c049997f7560"
      },
      "cell_type": "code",
      "source": [
        "print(\"=======================\")\n",
        "print(y_train.groupby(y_train).count())\n",
        "print(y_test.groupby(y_test).count())\n",
        "print(\"=======================\")\n",
        "print(type(x_train).__name__)\n",
        "print(x_train.shape)\n",
        "print(type(x_train.to_frame()).__name__)\n",
        "print((x_train.to_frame()).shape)\n",
        "\n",
        "x_train_1 = x_train\n",
        "x_test_1 = x_test\n",
        "y_train_1 = y_train\n",
        "y_test_1 = y_test\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=======================\n",
            "class\n",
            "0    3377\n",
            "1     523\n",
            "Name: class, dtype: int64\n",
            "class\n",
            "0    1448\n",
            "1     224\n",
            "Name: class, dtype: int64\n",
            "=======================\n",
            "Series\n",
            "(3900,)\n",
            "DataFrame\n",
            "(3900, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7PizT_76GURV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.to_frame()\n",
        "x_test = x_test.to_frame()\n",
        "y_train = y_train.to_frame()\n",
        "y_test = y_test.to_frame()\n",
        "\n",
        "\n",
        "train = x_train.join(y_train)\n",
        "test = x_test.join(y_test)\n",
        "\n",
        "x_train_merged_doc = train.groupby('class')['data'].apply('.'.join).reset_index()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aB4ZOqADGURd",
        "colab_type": "code",
        "colab": {},
        "outputId": "3dd74fff-381c-4b15-9b7b-914813364d93"
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3900, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "ZzBxvxjJGUR7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Null accuracy : accuracy by always predicting the most frequent class #"
      ]
    },
    {
      "metadata": {
        "id": "EpnUqSVNGUSB",
        "colab_type": "code",
        "colab": {},
        "outputId": "58430102-36e3-43ef-921f-4a6fcbec59cf"
      },
      "cell_type": "code",
      "source": [
        "print(y_test[\"class\"].value_counts())\n",
        "\n",
        "#calculate null accuracy for binary classifier\n",
        "print(\"\\nNull Accuracy : \" + str(max((y_test[\"class\"].mean()), (1-(y_test[\"class\"].mean())))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    1448\n",
            "1     224\n",
            "Name: class, dtype: int64\n",
            "\n",
            "Null Accuracy : 0.866028708134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uQUIGd92GUST",
        "colab_type": "code",
        "colab": {},
        "outputId": "2474ce1b-e4d1-4edc-e80a-97af231c89f6"
      },
      "cell_type": "code",
      "source": [
        "## creating TFIDF features\n",
        "#vectorizer = TfidfVectorizer(ngram_range=(1, 2),  sublinear_tf = True, stop_words='english')\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2),sublinear_tf = True, stop_words='english', max_df=0.5)\n",
        "#vectorizer.fit(raw_documents = x_train_merged_doc['data'], y = x_train_merged_doc['class'])\n",
        "#features_train_transformed   = vectorizer.transform(raw_documents=x_train, copy = False)\n",
        "features_train_transformed    = vectorizer.fit_transform(raw_documents=x_train['data'])\n",
        "features_test_transformed     = vectorizer.transform(raw_documents=x_test['data'], copy = False)\n",
        "\n",
        "print('=======================')\n",
        "print(features_train_transformed.shape)\n",
        "print('=======================')\n",
        "print(features_test_transformed.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=======================\n",
            "(3900, 28303)\n",
            "=======================\n",
            "(1672, 28303)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": false,
        "id": "ZwXbq3LrGUSl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Using the classic Naive Bayes classifier which is a proven classification technique for SPAM / HAM problem\n"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "za-MsDMlGUSq",
        "colab_type": "code",
        "colab": {},
        "outputId": "fcc4e60a-d37f-4c1a-994f-9c3115235451"
      },
      "cell_type": "code",
      "source": [
        "mnb = MultinomialNB(alpha=1e-10, fit_prior=True)\n",
        "mnb.fit(X=features_train_transformed, y=np.char.mod('%d',y_train['class'].values))\n",
        "pred_y = mnb.predict(features_test_transformed)\n",
        "actual_y = np.char.mod('%d',y_test['class'].values)\n",
        "cf_matrix = metrics.confusion_matrix(actual_y, pred_y)\n",
        "\n",
        "TP = cf_matrix[1,1]\n",
        "FN = cf_matrix[1,0]\n",
        "FP = cf_matrix[0,1]\n",
        "TN = cf_matrix[0,0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "True\n",
            "1\n",
            "True\n",
            "1\n",
            "True\n",
            "1\n",
            "True\n",
            "0\n",
            "True\n",
            "0\n",
            "True\n",
            "0\n",
            "True\n",
            "0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UceGnrr7GUS7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Classification Accuracy"
      ]
    },
    {
      "metadata": {
        "id": "j60W7GjBGUTA",
        "colab_type": "code",
        "colab": {},
        "outputId": "3ee8725e-2f66-4f59-8ea1-bfefee3f663f"
      },
      "cell_type": "code",
      "source": [
        "#metrics.accuracy_score(actual_y, pred_y)\n",
        "print(\"Classification accuracy : \" + str(((TP+TN)/float(TP+TN+FP+FN))*100) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 98.1459330144%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UPpOqToyGUTe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Classification Error"
      ]
    },
    {
      "metadata": {
        "id": "9vovokE8GUTi",
        "colab_type": "code",
        "colab": {},
        "outputId": "3bedb887-8cfb-4b21-ad38-f22a5ac0c9ca"
      },
      "cell_type": "code",
      "source": [
        "# 1-metrics.accuracy_score(actual_y, pred_y)\n",
        "print(\"Classification Error : \" + str(((FP+FN)/float(TP+TN+FP+FN))*100) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Error : 1.85406698565%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uVNyx96nGUTw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sensitivity : When actual value is +ve, how often is the prediction correct"
      ]
    },
    {
      "metadata": {
        "id": "jGV06Z5zGUTz",
        "colab_type": "code",
        "colab": {},
        "outputId": "6e6867ae-2128-484f-8ebf-dbe5b25522a6"
      },
      "cell_type": "code",
      "source": [
        "#print(metrics.recall_score(actual_y, pred_y))\n",
        "print(\"Sensitivity : \" + str(((TP)/float(TP+FN))*100) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitivity : 91.9642857143%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Il_Sl5t3GUUB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Specificity : When actual vaue is -ve, how ofen is the prediction correct"
      ]
    },
    {
      "metadata": {
        "id": "dVXge6bwGUUE",
        "colab_type": "code",
        "colab": {},
        "outputId": "c60064e3-60f8-49ca-f925-0198b25d6923"
      },
      "cell_type": "code",
      "source": [
        "print(\"Specificity : \" + str(TN/float(TN+FP)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Specificity : 0.991022099448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z5F68NANGUUM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### > The model is very likely to predict the -ve instance correctly compared to +ve instances.\n",
        "\n",
        "#### > Hence, we can define our classifier as highly Specific but not highly Sensitive\n",
        "\n",
        "#### > The primary reason is imbalanced distribution of response variable. We can suspect the computation of prior's of each class in the training phase might have high variance from sample to sample owing to low Sensitivity.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "blgI68AKGUUP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Precision : Ability to find -ve examples i.e. how much biased is the classifier towards +ve examples"
      ]
    },
    {
      "metadata": {
        "id": "It4lWbYIGUUR",
        "colab_type": "code",
        "colab": {},
        "outputId": "bfeefc25-2c04-4747-f692-81b1a22a6ef0"
      },
      "cell_type": "code",
      "source": [
        "#print(\"Precision : \" + str(metrics.precision_score(actual_y, pred_y)))\n",
        "print(\"Precision : \" + str(TP/float(TP+FP)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision : 0.940639269406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X6GULcGtGUUd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Recall : Ability to find +ve examples i.e. how good the classifier is in finding the +ve examples"
      ]
    },
    {
      "metadata": {
        "id": "oUQc0FcWGUUf",
        "colab_type": "code",
        "colab": {},
        "outputId": "f471b809-9b72-4ed2-cc59-3775a4bb81bb"
      },
      "cell_type": "code",
      "source": [
        "print(\"Recall : \" + str(TP/(TP+FN)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall : 0.919642857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uESTW62sGUUo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## balanced F-measure : weighted average of the precision and recall"
      ]
    },
    {
      "metadata": {
        "id": "qMHLjy0lGUUq",
        "colab_type": "code",
        "colab": {},
        "outputId": "6dcefe04-0bb6-4598-b9fb-3b66cf2e2dd5"
      },
      "cell_type": "code",
      "source": [
        "precision = TP/float(TP+FP)\n",
        "recall = TP/(TP+FN)\n",
        "\n",
        "F1 = 2*precision*recall/(precision + recall)\n",
        "\n",
        "print(\"F1 score : \" + str(F1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score : 0.930022573363\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}